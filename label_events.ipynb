{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f580b623",
   "metadata": {},
   "source": [
    "| Event | Variables & Percentiles | Duration | Label Code |\n",
    "|-------|------------------------|----------|------------|\n",
    "| **Heatwave** | TMAX ≥ P95 **and** TMIN ≥ P90 | ≥ 3 consec. days | 1 |\n",
    "| **Coldwave** | TMIN ≤ P5 | ≥ 2 days | 2 |\n",
    "| **Drought**  | 30‑day PRCP ≤ P10 **and** TAVG ≥ P80 | rolling 30 d | 3 |\n",
    "| **Flood**    | PRCP ≥ P99 **or** (SNOW ≥ P90 & TAVG > 0 °C within 3 d) | 1 day | 4 |\n",
    "| **Blizzard** | SNOW ≥ P90 **and** AWND ≥ P90 **and** TMAX ≤ P10 | 1 day | 5 |\n",
    "| **Extreme Wind** | AWND ≥ P95 | 1 day | 6 |\n",
    "| **Thunderstorm** | WT03 flag *or* (PRCP ≥ P80 & AWND ≥ P80) | 1 day | 7 |\n",
    "| **Compound** | ≥ 2 different events in 14‑day window | 14 d window | 99 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b3b766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded, shape: (383565, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load processed daily data\n",
    "DF_PATH = \"data/merged_pca.csv\"\n",
    "df = pd.read_csv(DF_PATH, parse_dates=[\"DATE\"])\n",
    "print(\"Loaded, shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8333805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core variable list (must exist in df)\n",
    "VARS = [\"TMAX\", \"TMIN\", \"TAVG\", \"PRCP\", \"SNOW\", \"SNWD\", \"AWND\"]\n",
    "\n",
    "# Compute station‑wise percentiles\n",
    "pct_levels = [0.05, 0.10, 0.80, 0.90, 0.95, 0.99]\n",
    "percs = (\n",
    "    df.groupby(\"STATION\")[VARS]\n",
    "    .quantile(pct_levels)\n",
    "    .unstack(level=-1)\n",
    ")\n",
    "\n",
    "# Attach useful daily rolling sums (30‑day PRCP)\n",
    "df.sort_values(\"DATE\", inplace=True)\n",
    "df[\"PRCP_30d\"] = (\n",
    "    df.groupby(\"STATION\")[\"PRCP\"].transform(lambda x: x.rolling(30, min_periods=1).sum())\n",
    ")\n",
    "\n",
    "# Helper: fetch percentile value\n",
    "def p(station, var, q):\n",
    "    return percs.loc[station, (var, q)]\n",
    "\n",
    "# Allocate event flag columns\n",
    "event_cols = [\n",
    "    \"heatwave\",\n",
    "    \"coldwave\",\n",
    "    \"drought\",\n",
    "    \"flood\",\n",
    "    \"blizzard\",\n",
    "    \"wind_extreme\",\n",
    "    \"thunderstorm\",\n",
    "]\n",
    "for c in event_cols:\n",
    "    df[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1a2225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate station‑by‑station for percentile thresholds\n",
    "for stn, g in df.groupby(\"STATION\"):\n",
    "    idx = g.index\n",
    "    # Individual day flags ---------------------------------------------------\n",
    "    heat_cond = (g.TMAX >= p(stn, \"TMAX\", 0.95)) & (g.TMIN >= p(stn, \"TMIN\", 0.90))\n",
    "    cold_cond = g.TMIN <= p(stn, \"TMIN\", 0.05)\n",
    "    drought_cond = (g.PRCP_30d <= p(stn, \"PRCP\", 0.10)) & (g.TAVG >= p(stn, \"TAVG\", 0.80))\n",
    "    flood_cond = (\n",
    "        (g.PRCP >= p(stn, \"PRCP\", 0.99))\n",
    "        | (\n",
    "            (g.SNOW >= p(stn, \"SNOW\", 0.90))\n",
    "            & (g.TAVG.shift(-3).ffill() > 0)\n",
    "        )\n",
    "    )\n",
    "    blizzard_cond = (\n",
    "        (g.SNOW >= p(stn, \"SNOW\", 0.90))\n",
    "        & (g.AWND >= p(stn, \"AWND\", 0.90))\n",
    "        & (g.TMAX <= p(stn, \"TMAX\", 0.10))\n",
    "    )\n",
    "    wind_cond = g.AWND >= p(stn, \"AWND\", 0.95)\n",
    "    thund_cond = (g.PRCP >= p(stn, \"PRCP\", 0.80)) & (g.AWND >= p(stn, \"AWND\", 0.80))\n",
    "\n",
    "    # Apply min‑duration rolling conditions ----------------------------------\n",
    "    heatwave = heat_cond.rolling(3).sum() >= 3\n",
    "    coldwave = cold_cond.rolling(2).sum() >= 2\n",
    "\n",
    "    # Safe assignment with index alignment -----------------------------------\n",
    "    df.loc[idx, \"heatwave\"] = heatwave.reindex(idx, fill_value=False).astype(int)\n",
    "    df.loc[idx, \"coldwave\"] = coldwave.reindex(idx, fill_value=False).astype(int)\n",
    "    df.loc[idx, \"drought\"] = drought_cond.reindex(idx, fill_value=False).astype(int)\n",
    "    df.loc[idx, \"flood\"] = flood_cond.reindex(idx, fill_value=False).astype(int)\n",
    "    df.loc[idx, \"blizzard\"] = blizzard_cond.reindex(idx, fill_value=False).astype(int)\n",
    "    df.loc[idx, \"wind_extreme\"] = wind_cond.reindex(idx, fill_value=False).astype(int)\n",
    "    df.loc[idx, \"thunderstorm\"] = thund_cond.reindex(idx, fill_value=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7feff8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/merged_labeled.csv with 383565 rows and 25 columns\n"
     ]
    }
   ],
   "source": [
    "# Save -----------------------------------------------------------------------\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "df.to_csv(\"data/merged_labeled.csv\", index=False)\n",
    "print(\"Saved data/merged_labeled.csv with\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61a7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound label -------------------------------------------------------------\n",
    "window = 14\n",
    "rolling_sum = (\n",
    "    df[event_cols]\n",
    "    .astype(int)\n",
    "    .groupby(df[\"STATION\"])\n",
    "    .rolling(window)\n",
    "    .sum()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "df[\"compound\"] = (rolling_sum >= 2).any(axis=1)\n",
    "df[\"compound\"] = df[\"compound\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38eb6875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/merged_labeled.csv with 383565 rows and 25 columns\n"
     ]
    }
   ],
   "source": [
    "# Save -----------------------------------------------------------------------\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "df = df.drop(columns=\"PRCP_30d\")\n",
    "df.to_csv(\"data/merged_labeled.csv\", index=False)\n",
    "print(\"Saved data/merged_labeled.csv with\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
